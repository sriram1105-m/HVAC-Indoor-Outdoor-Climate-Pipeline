# HVAC Indoor vs Outdoor Climate Comparison: Real-Time Production ETL Pipeline using Azure Data Factory (ADF)

## Enterprise Data Engineering Project

<h1> Executive Summary </h1>

This project documents the delivery of an exterprise data engineering solution developed for a client responsible for facilities and energy management across multiple buildings. The objective was to design and implementa a reliable data platform that compares indoor climate conditions with external weather data in order to support HVAC optimisation, reduce energy consumption, and maintain occupant comfort.

I was responsible for the end-to-end design and implementation of the pipeline using Auzre native services, including Azure Data Factory, Azure Data Lake Storage Gen2, Azure SQL Database, and Azure Logic Apps. The solution integrates IoT sensor data with external weather data, applies validation and standardisation, and delivers a unified analytical dataset alongside automated anomaly alerts.

The platform supports historical analysis and near real-time operational monitoring, providing facilities teams with timely, trusted information while maintaining strong governance and auditability.

<h1> Business Context </h1>

The client operates HVAC systems across several facilities where energy efficiency, operational stability, and occupant comfort are key priorities. Indoor climate data is produced continuously by building-level sensors, while outdoor conditions are sourced from an external weather provider.

Before this solution was implemented, indoor and outdoor datasets were analysed in isolation. This limited the ability to understand how external conditions influenced HVAC eperformance and delayed the identification of inefficiencies or abnormal behaviour.

The purpose of this project was to establish a centralised and giverned data pipeline that unifies these data streams, enforces data quality standards, and delivers actionable outputs for both operational monitoring and analytical reporting.

<h1> Data Volumes and Processing Profile </h1>

The pipeline was designed and validated against realistic operational workloads:

- Indoor data generated by approximately **120 to 180 sensors** across multiple facilities
- Sensor readings produced at **2 to 5 minute intervals**
- Dailt ingestion volumes of approximately **250,000 to 450,000 records**
- Outdoor weather data refreshed at **5 minute intervals**
- Historical data retention of **12 to 18 months**
- End-to-End pipeline latency typically within **10 to 15 minutes** of event time

These characteristics informed decisions around orchestration, partitioning, validation rules, and alert thresholds.

# Architecture (End-to-End Pipeline)

![Master Pipeline](diagrams/pipelines/master.png)

<h1> Platform Architecture </h1>

The solution follows a layered architecture implemented using Azure Data Factory for orchestration and transformation, with Azure Data Lake Storage Gen2 as the primary storage layer.

## Raw Layer

The Raw layer captures source data exactly as received. Indoor IoT sensor data is ingested using Azure Data Factory Copy Activities, while outdoor weather data is retrieved using the ADF HTTP connector. Data is written to immutable, time-partitioned folders in ADLS Gen2 to preserve lineage and support reprocessing.

Key responsibilities:

- Preserve source fidelity
- Maintain ingestion traceability
- Support audit and replay scenarios

## Bronze Layer

In the Bronze layer, raw JSON data is converted into schema-aligned Parquet files. Separate data flows handle indoor sensor data and weather data, applying column mapping, naming standardisation, and basic type normalisation.

This layer establishes a consistent structural contract for downstream processing and improves storage efficiency and query performance.

Key responsibilities:

- Stabilise schemas
- Standardise structure
- Optimise analytical storage

## Silver Layer

The silver layer is responsible for data quality and consistency. Sensor readings are validated, duplicates are removed, and out-of-range values are flagged or excluded. Weather attributes are normalised into consistent units and validated against expected ranges.

This layer produces a governed dataset suitable for analytical consumption and operational use.

Key responsibilities:

- Enforce data quality rules
- Reduce noise and invalid readings
- Produce reliable, standardised datasets

## Gold Layer

The Gold layer delivers business-facing analytical outputs. Indoor and outdoor datasets are joined on aligned event timestamps to produce a unified view of climate conditions.

Derived metrics include:

- Temperature delta between indoor and outdoor readings
- Humidity delta
- Time-based aggregations for operational reporting

Gold datasets are written to ADLS Gen2 for scalable storage and to Azure SQL Database to support BI dashboards and reporting workloads.

Key responsibilities:

- Deliver analytics-ready data
- Support reporting and operational insights

# Near Real Time Anomaly Detection

To support operational monitoring, the pipeline integrates with Azure Logic Apps. Once gold data is produced, rule-based evaluations are triggered to detect abnormal conditions, such as sustained temperature or humidity thresholds being breached.

Alerts are delivered to operational teams via email or collaboration tools, enabling timely investigation and intervention when HVAC systems deviate from expected behaviour.

# Orchestration and Reliability

A master orchestration pipeline built in Azure Data Factory coordinates the execution of indoor and outdoor processing flows. Pipelines run in parallel and converge at the Gold layer.

Operational features include:

- Parameterised pipelines to support reuse across facilities
- Retry policies and controlled failure handling
- Dependency management across layers
- Modular design to support future expansion

This approach ensures predictable execution and operational resilience.

# Engineering Decisions and Rationale

Key design decisions were driven by operational and enterprise requirements:

- Azure Data Factory was selected to centralise orchestration and simplify operational management
- Parquet was adopted as the primary analytical format to balance performance and cost
- Time-based partitioning was applied to support efficient incremental processing
- Managed Identity was used for secure access to Azure SQL and storage resources
- Columnstore indexing was applied in Azure SQL to support analytical query patterns

These decisions prioritise security, performance, and long-term maintainability.

# Business Outcomes

The delivered platform enables:

- Unified analysis of indoor and outdoor climate conditions
- Faster identification of HVAC anomalies and inefficiencies
- Data-informed optimisation of energy usage
- Improved occupant comfort through timely response
- A scalable foundation for extending monitoring to additional facilities

# Professional Scope and Role Alignment

This project reflects responsibilities typically performed by a Data Engineer working in an enterprise environment, including:

- Designing and implementing end-to-end data pipelines
- Integrating IoT and external API data sources
- Building governed, scalable data architectures
- Supporting both analytical and operational use cases
- Delivering production-grade data platforms

# Data Availability and Confidentiality

This repository contains representative and anonymised sample datasets used to illustrate pipeline structure, transformations, and orchestration logic.

Original client data and production-scale datasets are not included due to confidentiality and data protection obligations.

The architecture, validation logic, orchestration patterns, and operational characteristics documented in this repository reflect the production implementation.


# Repository Layout
```
HVAC-Indoor-Outdoor-Climate-Pipeline/
│
├── arm_template/             → ARM export of ADF pipelines
├── diagrams/pipelines/       → Screenshots of ADF dataflows & master pipeline
├── hvac-indoor-outdoor-etl/  → Sample datasets (raw, bronze, silver, gold)
├── sql/                      → SQL DDLs and queries for Gold tables
└── README.md                 → Project documentation

```
# Author

Data Engineer with experience delivering Azure-native data platforms, integrating IoT and API data sources, and supporting operational and analytical workloads in production environments.

For further discussion or a technical walkthrough of this project, please feel free to get in touch.
